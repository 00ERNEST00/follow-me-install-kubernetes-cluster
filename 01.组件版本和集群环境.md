<!-- toc -->

tags: kubernetes, environment

# 组件版本和集群环境

## 集群组件和版本

+ Kubernetes 1.10.4
+ Docker 18.03.1-ce
+ Etcd 3.3.7
+ Flanneld 0.10.0 vxlan
+ 安全：TLS 认证通信 (所有组件，如 etcd、kubernetes master 和 node)，周期自动轮转 kubelet TLS 证书，RBAC 授权；
+ kubelet：kublet.config 配置文件，TLS BootStrapping Token，自动 approve CSR；
+ 插件：coredns、dashboard、heapster (influxdb、grafana)、EFK (elasticsearch、fluentd、kibana)；
+ 镜像仓库：docker registry 和 harbor;

## 集群机器

+ kube-node1：172.27.129.105
+ kube-node2：172.27.129.111
+ kube-node3：172.27.129.112

vagrant 目录下提供了 Vagrantfile 文件，你可以使用 vagrant 和 virtualbox 创建对应的三台虚机：

``` bash
$ cd vagrant
$ vagrant up
```

本着测试的目的，etcd 集群、kubernetes master、kubernetes node 均使用这三台机器。

修改每台机器的 `/etc/hosts` 文件，添加主机名和 IP 的对应关系：

``` bash
$ grep kube-node /etc/hosts
172.27.129.105 kube-node1	kube-node1
172.27.129.111 kube-node2	kube-node2
172.27.129.112 kube-node3	kube-node3
```

## 集群环境变量

后续的部署步骤将使用下面定义的全局环境变量，根据**自己的机器、网络情况**修改：

``` bash
#!/usr/bin/bash

# 生成 EncryptionConfig 所需的加密 key
ENCRYPTION_KEY=$(head -c 32 /dev/urandom | base64)

# 最好使用 主机未用的网段 来定义服务网段和 Pod 网段

# 服务网段 (Service CIDR），部署前路由不可达，部署后集群内使用IP:Port可达
SERVICE_CIDR="10.254.0.0/16"

# POD 网段 (Cluster CIDR），部署前路由不可达，**部署后**路由可达(flanneld保证)
CLUSTER_CIDR="172.30.0.0/16"

# 服务端口范围 (NodePort Range)
export NODE_PORT_RANGE="8400-9000"

# 集群所有机器 IP
export NODE_IPS=(172.27.129.105 172.27.129.111 172.27.129.112)

# 集群各 IP 对应的 主机名
export NODE_NAMES=(kube-node1 kube-node2 kube-node3)

# etcd 集群服务地址列表
export ETCD_ENDPOINTS="https://172.27.129.105:2379,https://172.27.129.111:2379,https://172.27.129.112:2379"

# etcd 集群间通信的IP和端口
export ETCD_NODES="kube-node1=https://172.27.129.105:2380,kube-node2=https://172.27.129.111:2380,kube-node3=https://172.27.129.112:2380"

# flanneld 网络配置前缀
export FLANNEL_ETCD_PREFIX="/kubernetes/network"

# kubernetes 服务 IP (一般是 SERVICE_CIDR 中第一个IP)
export CLUSTER_KUBERNETES_SVC_IP="10.254.0.1"

# 集群 DNS 服务 IP (从 SERVICE_CIDR 中预分配)
export CLUSTER_DNS_SVC_IP="10.254.0.2"

# 集群 DNS 域名
export CLUSTER_DNS_DOMAIN="cluster.local."

# 将二进制目录 /opt/k8s/bin 加入到 PATH 中
export PATH=/opt/k8s/bin:$PATH
```
+ 打包后的变量定义见 [environment.sh](https://github.com/opsnull/follow-me-install-kubernetes-cluster/blob/master/manifests/environment.sh)，后续部署时会**提示导入**该脚本；

## 分发集群环境变量定义脚本

把全局变量定义脚本拷贝到**所有**机器的 `/opt/k8s/bin` 目录：

``` bash
$ cp environment.sh /opt/k8s/bin
$ chmod +x /opt/k8s/bin/*
```

## 认证和授权

本文档开启了严格的安全认证和授权机制，包括但不限于：
+ 后续 `kube-apiserver` 使用 `RBAC` 对客户端(如 `kubelet`、`kube-proxy`、`Pod`)请求进行授权；
+ `kube-apiserver` 预定义了一些 `RBAC` 使用的 `RoleBindings`，如 `cluster-admin` 将 Group `system:masters` 与 Role `cluster-admin` 绑定，该 Role 授予了调用`kube-apiserver` **所有 API**的权限；
+ O 指定该证书的 Group 为 `system:masters`，`kubelet` 使用该证书访问 `kube-apiserver` 时 ，由于证书被 CA 签名，所以认证通过，同时由于证书用户组为经过预授权的 `system:masters`，所以被授予访问所有 API 的权限；
+ hosts 属性值为空列表；

## 网段

POD 网段
Cluster Service 网段